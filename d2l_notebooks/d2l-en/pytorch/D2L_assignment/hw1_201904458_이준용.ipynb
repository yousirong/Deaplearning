{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIVgtna6-Mae"
   },
   "source": [
    "\n",
    "**Homework #1. linear regression model**\n",
    "\n",
    "###이번 실습의 학습 목표 입니다.\n",
    "1. 주어진 데이터를 불러오는 과정 익히기.\n",
    "2. train loader & test loader 만들기.\n",
    "3. model에 들어갈 input data preprocessing 해보기.\n",
    "4. 간단한 linear regression model 구현해보기.\n",
    "5. pytorch에 구현되어있는 loss function, optimizer 사용해보기.\n",
    "6. 학습과정에서의 이해를 돕기 위해 기능들이 수행하는 역할에 대해 공부하기.\n",
    "\n",
    " + input값 채우기.\n",
    "7.  Linear regression이 왜 Neural network인지 해당 과제를 예시로 들어 설명하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qauQvRmaP8qg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import dataloader\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device is cpu\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print('Current cuda device is', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGRfLpyxE38d"
   },
   "source": [
    "* 주어진 데이터를 불러오는 과정 익히기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mX4aOpYuQWWi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data len :  60000\n",
      "test data len :  10000\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "training_data=MNIST(root=\"./\", train=True, download=True, transform=ToTensor())\n",
    "test_data=MNIST(root=\"./\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "print(\"training data len : \",len(training_data))\n",
    "print(\"test data len : \",len(test_data))\n",
    "print(training_data)\n",
    "\n",
    "# data image 9장 불러오기 - 'import matplotlib.pyplot as plt' 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pg-0VpaaFAht"
   },
   "source": [
    "* train loader & test loader 만들기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_y2syXETHiW"
   },
   "outputs": [],
   "source": [
    "# train loader & test loader 만들기 (batch size : 32/ train : shuffle=True, test : shuffle=False)\n",
    "# 데이터셋을 DataLoader에 넣어 Train Loader와 Test Loader를 생성합니다.\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32  # 미니배치 크기를 32로 설정합니다.\n",
    "shuffle_train = True  # 학습 데이터(shuffle_train)은 데이터를 섞음\n",
    "shuffle_test = False  # 테스트 데이터(shuffle_test)는 섞지 않음.\n",
    "\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=shuffle_train)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=shuffle_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pq_LMfmFKQ4"
   },
   "source": [
    "* input data preprocessing 해보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyNh8ohwWmdS"
   },
   "outputs": [],
   "source": [
    "# x_values = [i for i in range(11)]\n",
    "# x_train = () # numpy를 사용하여 input data를 배열 형태로 만들기(type=np.float32)\n",
    "# x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "# y_values = [2*i + 1 for i in x_values]\n",
    "# y_train = () # numpy를 사용하여 input data를 배열 형태로 만들기(type=np.float32)\n",
    "# y_train = y_train.reshape(-1, 1)\n",
    "import numpy as np\n",
    "\n",
    "x_values = np.array([i for i in range(11)], dtype=np.float32)\n",
    "x_train = x_values.reshape(-1, 1)\n",
    "\n",
    "y_values = np.array([2*i + 1 for i in x_values], dtype=np.float32)\n",
    "y_train = y_values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubjA6CgVFUZ5"
   },
   "source": [
    "* 간단한 linear regression model 구현해보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAGkzd3oVN2K"
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # 선형 레이어 초기화: 입력 차원 -> 출력 차원\n",
    "        self.linear = nn.Linear(inputSize, outputSize)\n",
    "#super()로 기반 클래스(부모 클래스)를 초기화해줌으로써,\n",
    "# 기반 클래스의 속성을 subclass가 받아오도록 한다. (초기화를 하지 않으면, 부모 클래스의 속성을 사용할 수 없음)\n",
    "# 좀 더 명확하게 super를 사용하기 위해서는 단순히 super().__init__()을 하는 것이 아니라 super(파생클래스, self).__init__() 을 해준다.\n",
    "#이와 같이 적어주면 기능적으로 차이는 없지만, 파생클래스와 self를 넣어서 현재 클래스가 어떤 클래스인지 명확하게 표시해줄 수 있다.\n",
    "    def forward(self, x):\n",
    "        # 순전파 연산: 선형 레이어를 통한 입력 데이터 변환\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CMbd7meWw6s"
   },
   "outputs": [],
   "source": [
    "inputDim = 1 # 'x'의 차원이 1이 되는 이유를 설명하시오. :\n",
    "\n",
    "#Linear Regression 모델은 주로 하나의 입력 변수를 기반으로 하여 출력 변수를 예측하는 간단한 선형 모델입니다.\n",
    "# 입력 변수 'x'가 하나의 차원을 가질 때, 예측 문제는 'x'를 사용하여 'y'를 예측하는 문제가 되며, 이는 하나의 입력 차원을 가지는 것을 의미합니다.\n",
    "#예를 들어, 주택 가격을 예측하는 경우, \n",
    "#주택 크기 (제곱 피트)를 입력으로 사용할 때 'inputDim'은 1이 됩니다.\n",
    "\n",
    "outputDim = 1 # 'y'의 차원이 1이 되는 이유를 설명하시오. :\n",
    "\n",
    "#Linear Regression 모델은 연속형 값을 예측하는 회귀 문제를 다룹니다. \n",
    "#따라서 예측된 값 'y'의 출력 차원은 1이 됩니다. Linear Regression 모델은 하나의 연속형 값을 예측하므로 'outputDim'은 1이 됩니다. \n",
    "#다시 주택 가격 예측 예를 들면, 모델의 출력은 예상 가격으로 하나의 값만을 예측합니다.\n",
    "learningRate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "model = LinearRegression(inputDim, outputDim)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iWxqEP_G7Ci"
   },
   "source": [
    "* pytorch에 구현되어있는 loss function, optimizer 사용해보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J39lCIf3GRhZ"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss() \n",
    "# 주어진 코드에서 loss_fn을 MSE (Mean Squared Error) Loss Function으로 설정하려고 합니다. \n",
    "# MSE는 회귀 문제에서 예측값과 실제값 간의 평균 제곱 오차를 계산하는 함수로, \n",
    "# 이를 최소화하는 것이 회귀 모델의 목표입니다.\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "#주어진 코드에서 optimizer를 SGD (Stochastic Gradient Descent) Optimizer로 설정하려고 합니다.\n",
    "# SGD는 모델의 가중치를 업데이트하는 최적화 알고리즘 중 하나로, \n",
    "# 학습률(learning rate)과 같은 하이퍼파라미터를 사용하여 모델 파라미터를 조정합니다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ethk4y9eHJuv"
   },
   "source": [
    "* 학습과정에서의 이해를 돕기 위해 기능들이 수행하는 역할에 대해 공부하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1a2CTu5Wzkw"
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
    "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
    "    else:\n",
    "        inputs = Variable(torch.from_numpy(x_train))\n",
    "        labels = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    # optimizer를 zero_grad 시키는 이유: 이전 미니배치의 그래디언트 정보를 초기화하여 현재 미니배치의 그래디언트로 업데이트하기 위함입니다.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 모델을 통해 입력 데이터를 순전파하여 예측값을 얻습니다.\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # 손실 함수를 사용하여 예측값과 실제값 간의 오차(loss)를 계산합니다.\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    print(loss)\n",
    "\n",
    "    # loss function을 backward 시키는 이유: 오차(loss)를 모델 파라미터에 대해 미분하여 그래디언트를 계산하고, 이를 사용하여 모델 파라미터를 업데이트합니다.\n",
    "    loss.backward()\n",
    "\n",
    "    # Optimizer를 사용하여 모델 파라미터를 업데이트합니다.\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I31foyPTW2J8"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    if torch.cuda.is_available():\n",
    "        predicted = model(Variable(torch.from_numpy(x_train).cuda())).cpu().data.numpy()\n",
    "    else:\n",
    "        predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "    print(predicted)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQcS5oIAHuET"
   },
   "source": [
    "* Linear regression이 왜 Neural network인지 해당 과제를 예시로 들어 설명하기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S16gX4x7HwUJ"
   },
   "source": [
    " Linear Regression이 왜 Neural Network의 한 형태로 볼 수 있는지 설명하겠습니다.\r\n",
    "\r\n",
    "Neural Network의 핵심 구성 요소 중 하나는 뉴런(노드)입니다. 각 뉴런은 입력값에 대한 가중치를 가지고, 이 가중치를 사용하여 입력값을 변환하고 활성화 함수를 통과시킵니다. 이런 관점에서 Linear Regression 모델은 Neural Network의 가장 간단한 형태 중 하나입니다.\r\n",
    "\r\n",
    "1. **입력층(Input Layer):** Linear Regression에서 입력 변수(x)는 입력층에 해당합니다. 입력층은 데이터의 특성(feature)을 나타내며, 이 특성에 대한 가중치(weight)를 곱하고 합산하여 출력을 계산합니다.\r\n",
    "\r\n",
    "2. **가중치(Weight):** Linear Regression에서는 가중치가 각 입력 변수와 관련이 있습니다. Neural Network의 뉴런과 마찬가지로 Linear Regression의 입력 변수에 가중치를 곱하여 가중합을 계산합니다.\r\n",
    "\r\n",
    "3. **활성화 함수(Activation Function):** Linear Regression에서는 활성화 함수를 사용하지 않습니다. 그러나 Neural Network의 다른 형태에서는 비선형 활성화 함수(예: 시그모이드, 렐루)를 사용하여 뉴런의 출력을 변환합니다.\r\n",
    "\r\n",
    "4. **출력(Output Layer):** Linear Regression에서 출력은 예측값을 나타냅니다. Neural Network에서도 출력층이 있고, 여기에서 최종 예측이 이루어집니다.\r\n",
    "\r\n",
    "5. **Loss Function과 최적화(Optimization):** Neural Network와 마찬가지로 Linear Regression에서도 Loss Function을 사용하여 예측값과 실제값 간의 오차를 계산하고, 이 오차를 최소화하기 위해 최적화 알고리즘을 사용합니다. 주로 평균 제곱 오차(Mean Squared Error, MSE)를 사용하며, 이를 최소화하기 위해 경사 하강법(Gradient Descent)을 적용합니다.\r\n",
    "\r\n",
    "따라서 Linear Regression은 입력 변수와 가중치를 조합하여 출력을 계산하는 모델로, 이러한 모델은 Neural Network의 가장 간단한 형태 중 하나로 볼 수 있습니다. 뉴런, 가중치, 활성화 함수, 출력층, Loss Function, 최적화와 같은 개념은 Neural Network와 Linear Regression 간에 공통적으로 사용되며, Neural Network는 이러한 개념을 확장하여 더 복잡한 데이터 패턴을 모델링할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
