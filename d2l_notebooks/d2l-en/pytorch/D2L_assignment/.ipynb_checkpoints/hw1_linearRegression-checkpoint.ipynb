{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Homework #1. linear regression model**\n",
        "\n",
        "###이번 실습의 학습 목표 입니다.\n",
        "1. 주어진 데이터를 불러오는 과정 익히기.\n",
        "2. train loader & test loader 만들기.\n",
        "3. model에 들어갈 input data preprocessing 해보기.\n",
        "4. 간단한 linear regression model 구현해보기.\n",
        "5. pytorch에 구현되어있는 loss function, optimizer 사용해보기.\n",
        "6. 학습과정에서의 이해를 돕기 위해 기능들이 수행하는 역할에 대해 공부하기.\n",
        "\n",
        " + input값 채우기.\n",
        "7.  Linear regression이 왜 Neural network인지 해당 과제를 예시로 들어 설명하기."
      ],
      "metadata": {
        "id": "aIVgtna6-Mae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qauQvRmaP8qg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import dataloader\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 주어진 데이터를 불러오는 과정 익히기."
      ],
      "metadata": {
        "id": "rGRfLpyxE38d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data=MNIST(root=\"./\", train=True, download=True, transform=ToTensor())\n",
        "test_data=MNIST(root=\"./\", train=False, download=True, transform=ToTensor())\n",
        "\n",
        "print(\"training data len : \",len(training_data))\n",
        "print(\"test data len : \",len(test_data))\n",
        "\n",
        "# data image 9장 불러오기 - 'import matplotlib.pyplot as plt' 사용\n"
      ],
      "metadata": {
        "id": "mX4aOpYuQWWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* train loader & test loader 만들기."
      ],
      "metadata": {
        "id": "pg-0VpaaFAht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train loader & test loader 만들기 (batch size : 32/ train : shuffle=True, test : shuffle=False)\n",
        "train_loader = DataLoader()\n",
        "test_loader = DataLoader()"
      ],
      "metadata": {
        "id": "F_y2syXETHiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* input data preprocessing 해보기."
      ],
      "metadata": {
        "id": "-pq_LMfmFKQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_values = [i for i in range(11)]\n",
        "x_train = () # numpy를 사용하여 input data를 배열 형태로 만들기(type=np.float32)\n",
        "x_train = x_train.reshape(-1, 1)\n",
        "\n",
        "y_values = [2*i + 1 for i in x_values]\n",
        "y_train = () # numpy를 사용하여 input data를 배열 형태로 만들기(type=np.float32)\n",
        "y_train = y_train.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "vyNh8ohwWmdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 간단한 linear regression model 구현해보기."
      ],
      "metadata": {
        "id": "ubjA6CgVFUZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class linearRegression(torch.nn.Module):\n",
        "    def __init__(self, inputSize, outputSize):\n",
        "      super('').__init__()\n",
        "      self.linear = torch.nn.Linear('')\n",
        "\n",
        "    def forward(self, x):\n",
        "      ''\n",
        "        return out"
      ],
      "metadata": {
        "id": "uAGkzd3oVN2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputDim = 1 # 'x'의 차원이 1이 되는 이유를 설명하시오. :\n",
        "outputDim = 1 # 'y'의 차원이 1이 되는 이유를 설명하시오. :\n",
        "learningRate = 0.01\n",
        "epochs = 100\n",
        "\n",
        "model = linearRegression(inputDim, outputDim)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()"
      ],
      "metadata": {
        "id": "1CMbd7meWw6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* pytorch에 구현되어있는 loss function, optimizer 사용해보기."
      ],
      "metadata": {
        "id": "3iWxqEP_G7Ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = () # MSE loss function\n",
        "optimizer = () # SGD optimizer"
      ],
      "metadata": {
        "id": "J39lCIf3GRhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 학습과정에서의 이해를 돕기 위해 기능들이 수행하는 역할에 대해 공부하기."
      ],
      "metadata": {
        "id": "Ethk4y9eHJuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
        "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
        "    else:\n",
        "        inputs = Variable(torch.from_numpy(x_train))\n",
        "        labels = Variable(torch.from_numpy(y_train))\n",
        "\n",
        "    # optimizer를 zero_grad 시키는 이유를 본인이 이해한 언어로 (주석으로) 설명하기 - 동일한 대답이 나올 경우, 0점 처리\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model() # output 안에 들어가야할 값 채우기\n",
        "\n",
        "    loss = loss_fn(,) # criterion 안에 들어가야할 값 채우기\n",
        "    print(loss)\n",
        "\n",
        "    # loss function을 backward 시키는 이유를 본인이 이해한 언어로 (주석으로) 설명하기 - 동일한 대답이 나올 경우, 0점 처리\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
      ],
      "metadata": {
        "id": "V1a2CTu5Wzkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    if torch.cuda.is_available():\n",
        "        predicted = model(Variable(torch.from_numpy(x_train).cuda())).cpu().data.numpy()\n",
        "    else:\n",
        "        predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
        "    print(predicted)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
        "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I31foyPTW2J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Linear regression이 왜 Neural network인지 해당 과제를 예시로 들어 설명하기."
      ],
      "metadata": {
        "id": "yQcS5oIAHuET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " :"
      ],
      "metadata": {
        "id": "S16gX4x7HwUJ"
      }
    }
  ]
}